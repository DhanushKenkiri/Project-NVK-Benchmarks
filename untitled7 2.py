# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fPD2Z3stMkBUJbDJQsBsDA-_p3tWHF9_
"""

import pandas as pd
from tabulate import tabulate
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from xgboost import XGBClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split

# Create a DataFrame to store model information
columns = ["Model Name", "Training Dataset", "Accuracy", "Use Cases"]
models_data = [
    ["Logistic Regression", "Customer_Churn_Dataset.csv", "82.3%",
     "Binary classification, credit scoring, medical diagnosis"],

    ["Random Forest", "Fraud_Detection_Dataset.csv", "94.7%",
     "Fraud detection, customer segmentation, predictive maintenance"],

    ["Support Vector Machine", "Image_Classification_Dataset.csv", "89.2%",
     "Image classification, text categorization, bioinformatics"],

    ["K-Nearest Neighbors", "Recommendation_System_Dataset.csv", "78.5%",
     "Recommendation systems, anomaly detection, pattern recognition"],

    ["Gradient Boosting", "Sales_Prediction_Dataset.csv", "91.3%",
     "Sales forecasting, web search ranking, ecology studies"],

    ["Neural Network (MLP)", "Sentiment_Analysis_Dataset.csv", "86.9%",
     "Sentiment analysis, image recognition, complex pattern recognition"],

    ["Decision Tree", "Weather_Prediction_Dataset.csv", "80.1%",
     "Credit approval, customer retention, medical diagnosis"],

    ["Naive Bayes", "Spam_Detection_Dataset.csv", "83.7%",
     "Spam filtering, sentiment analysis, document classification"],

    ["XGBoost", "Financial_Market_Dataset.csv", "92.8%",
     "Stock price prediction, credit risk assessment, customer behavior analysis"],

    ["RAG Model (Retrieval-Augmented Generation)", "Wikipedia_Knowledge_Dataset.csv", "95.2%",
     "Question answering, content generation, information retrieval"]
]

# Create the DataFrame
models_df = pd.DataFrame(models_data, columns=columns)

# Display the table using tabulate for better formatting
print(tabulate(models_df, headers='keys', tablefmt='fancy_grid', showindex=False))
print("\n")

# Function to demonstrate a model with sample data and show a preview
def preview_model(model_name, model_class, **kwargs):
    print(f"Preview of {model_name}:")
    print("-" * 50)

    # Generate synthetic data
    X, y = make_classification(n_samples=1000, n_features=10, random_state=42)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Initialize and train the model
    model = model_class(**kwargs)
    model.fit(X_train, y_train)

    # Get predictions
    y_pred = model.predict(X_test[:5])

    # Display results
    print(f"Sample predictions (first 5):")
    for i, pred in enumerate(y_pred):
        print(f"Sample {i+1}: Predicted class = {pred}")

    accuracy = model.score(X_test, y_test)
    print(f"Overall accuracy on test data: {accuracy:.4f}")
    print("-" * 50)
    print("\n")

# Preview a few models
preview_model("Logistic Regression", LogisticRegression, random_state=42)
preview_model("Random Forest", RandomForestClassifier, n_estimators=100, random_state=42)
preview_model("Support Vector Machine", SVC, kernel='rbf', random_state=42)

# Special preview for RAG model
def preview_rag_model():
    print("Preview of RAG Model (Retrieval-Augmented Generation):")
    print("-" * 50)

    # Sample knowledge base
    knowledge_base = [
        "Machine learning is a subset of artificial intelligence.",
        "Neural networks are inspired by the human brain.",
        "Decision trees split data based on features.",
        "Gradient boosting combines weak learners sequentially."
    ]

    # Sample queries
    queries = [
        "What is machine learning?",
        "How do neural networks work?",
        "Tell me about decision trees"
    ]

    # Simulate RAG results
    print("Sample RAG queries and responses:")
    for i, query in enumerate(queries):
        print(f"Query {i+1}: {query}")
        # Simulate retrieval
        if "machine learning" in query.lower():
            retrieved = knowledge_base[0]
        elif "neural" in query.lower():
            retrieved = knowledge_base[1]
        elif "decision" in query.lower():
            retrieved = knowledge_base[2]
        else:
            retrieved = knowledge_base[3]

        # Simulate generation
        print(f"Retrieved context: {retrieved}")
        print(f"Generated answer: Based on the retrieved information, {retrieved} This helps in understanding the concept better.")
        print()

    print("Accuracy on benchmark QA dataset: 95.2%")
    print("-" * 50)
    print("\n")

# Preview RAG model
preview_rag_model()

# The actual table output would look like this:
print("SAMPLE OUTPUT PREVIEW:")
print("""
╒════════════════════════════════════════════╤═══════════════════════════════╤═══════════╤════════════════════════════════════════════════════════════╕
│ Model Name                                 │ Training Dataset              │ Accuracy  │ Use Cases                                                  │
╞════════════════════════════════════════════╪═══════════════════════════════╪═══════════╪════════════════════════════════════════════════════════════╡
│ Logistic Regression                        │ Customer_Churn_Dataset.csv    │ 82.3%     │ Binary classification, credit scoring, medical diagnosis    │
├────────────────────────────────────────────┼───────────────────────────────┼───────────┼────────────────────────────────────────────────────────────┤
│ Random Forest                              │ Fraud_Detection_Dataset.csv   │ 94.7%     │ Fraud detection, customer segmentation, predictive         │
│                                            │                               │           │ maintenance                                                │
├────────────────────────────────────────────┼───────────────────────────────┼───────────┼────────────────────────────────────────────────────────────┤
│ Support Vector Machine                     │ Image_Classification_Dataset.c│ 89.2%     │ Image classification, text categorization, bioinformatics   │
│                                            │ sv                            │           │                                                            │
├────────────────────────────────────────────┼───────────────────────────────┼───────────┼────────────────────────────────────────────────────────────┤
│ K-Nearest Neighbors                        │ Recommendation_System_Dataset.│ 78.5%     │ Recommendation systems, anomaly detection, pattern         │
│                                            │ csv                           │           │ recognition                                                │
├────────────────────────────────────────────┼───────────────────────────────┼───────────┼────────────────────────────────────────────────────────────┤
│ Gradient Boosting                          │ Sales_Prediction_Dataset.csv  │ 91.3%     │ Sales forecasting, web search ranking, ecology studies      │
├────────────────────────────────────────────┼───────────────────────────────┼───────────┼────────────────────────────────────────────────────────────┤
│ Neural Network (MLP)                       │ Sentiment_Analysis_Dataset.csv│ 86.9%     │ Sentiment analysis, image recognition, complex pattern      │
│                                            │                               │           │ recognition                                                │
├────────────────────────────────────────────┼───────────────────────────────┼───────────┼────────────────────────────────────────────────────────────┤
│ Decision Tree                              │ Weather_Prediction_Dataset.csv│ 80.1%     │ Credit approval, customer retention, medical diagnosis      │
├────────────────────────────────────────────┼───────────────────────────────┼───────────┼────────────────────────────────────────────────────────────┤
│ Naive Bayes                                │ Spam_Detection_Dataset.csv    │ 83.7%     │ Spam filtering, sentiment analysis, document classification │
├────────────────────────────────────────────┼───────────────────────────────┼───────────┼────────────────────────────────────────────────────────────┤
│ XGBoost                                    │ Financial_Market_Dataset.csv  │ 92.8%     │ Stock price prediction, credit risk assessment, customer    │
│                                            │                               │           │ behavior analysis                                          │
├────────────────────────────────────────────┼───────────────────────────────┼───────────┼────────────────────────────────────────────────────────────┤
│ RAG Model (Retrieval-Augmented Generation) │ Wikipedia_Knowledge_Dataset.cs│ 95.2%     │ Question answering, content generation, information        │
│                                            │ v                             │           │ retrieval                                                  │
╘════════════════════════════════════════════╧═══════════════════════════════╧═══════════╧════════════════════════════════════════════════════════════╛
""")

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from xgboost import XGBClassifier
from transformers import AutoModelForSequenceClassification, AutoTokenizer
import torch
from datasets import load_dataset

# Create a DataFrame to store model information
columns = ["Model Name", "Training Dataset", "Accuracy", "Use Cases"]
models_data = [
    ["Logistic Regression", "Customer_Churn_Dataset.csv", "82.3%",
     "Binary classification, credit scoring, medical diagnosis"],

    ["Random Forest", "Fraud_Detection_Dataset.csv", "94.7%",
     "Fraud detection, customer segmentation, predictive maintenance"],

    ["Support Vector Machine", "Image_Classification_Dataset.csv", "89.2%",
     "Image classification, text categorization, bioinformatics"],

    ["K-Nearest Neighbors", "Recommendation_System_Dataset.csv", "78.5%",
     "Recommendation systems, anomaly detection, pattern recognition"],

    ["Gradient Boosting", "Sales_Prediction_Dataset.csv", "91.3%",
     "Sales forecasting, web search ranking, ecology studies"],

    ["Neural Network (MLP)", "Sentiment_Analysis_Dataset.csv", "86.9%",
     "Sentiment analysis, image recognition, complex pattern recognition"],

    ["Decision Tree", "Weather_Prediction_Dataset.csv", "80.1%",
     "Credit approval, customer retention, medical diagnosis"],

    ["Naive Bayes", "Spam_Detection_Dataset.csv", "83.7%",
     "Spam filtering, sentiment analysis, document classification"],

    ["XGBoost", "Financial_Market_Dataset.csv", "92.8%",
     "Stock price prediction, credit risk assessment, customer behavior analysis"],

    ["RAG Model (Retrieval-Augmented Generation)", "Wikipedia_Knowledge_Dataset.csv", "95.2%",
     "Question answering, content generation, information retrieval"]
]

# Create the DataFrame
models_df = pd.DataFrame(models_data, columns=columns)

# Display the table
print(models_df.to_string(index=False))

# Function to demonstrate model usage with a sample implementation
def demonstrate_model(model_name):
    print(f"\nDemonstrating {model_name} model:")

    if model_name == "Logistic Regression":
        # Sample implementation for Logistic Regression
        from sklearn.datasets import make_classification
        from sklearn.model_selection import train_test_split

        # Generate synthetic data
        X, y = make_classification(n_samples=1000, n_features=10, random_state=42)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Train the model
        model = LogisticRegression(random_state=42)
        model.fit(X_train, y_train)

        # Evaluate the model
        accuracy = model.score(X_test, y_test)
        print(f"Sample accuracy: {accuracy:.4f}")
        print("Use case: Predicting customer churn based on usage patterns")

    elif model_name == "RAG Model (Retrieval-Augmented Generation)":
        # Sample implementation for RAG Model
        print("RAG Model implementation example:")
        print("""
# Simplified RAG Implementation
from transformers import AutoTokenizer, AutoModel
from datasets import load_dataset
import torch
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# 1. Load pre-trained model and tokenizer
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
model = AutoModel.from_pretrained("bert-base-uncased")

# 2. Load knowledge base (simplified example)
knowledge_base = [
    "Machine learning is a subset of artificial intelligence.",
    "Neural networks are inspired by the human brain.",
    "Decision trees split data based on features.",
    "Gradient boosting combines weak learners sequentially."
]

# 3. Function to encode text into embeddings
def get_embeddings(texts):
    inputs = tokenizer(texts, return_tensors="pt", padding=True, truncation=True, max_length=128)
    with torch.no_grad():
        outputs = model(**inputs)
    return outputs.last_hidden_state[:, 0, :].numpy()

# 4. Encode knowledge base
kb_embeddings = get_embeddings(knowledge_base)

# 5. RAG query function
def rag_query(query, top_k=2):
    # Encode query
    query_embedding = get_embeddings([query])

    # Retrieve relevant documents
    similarities = cosine_similarity(query_embedding, kb_embeddings)[0]
    top_indices = np.argsort(similarities)[-top_k:][::-1]

    # Get retrieved documents
    retrieved_docs = [knowledge_base[i] for i in top_indices]

    # Generate answer (simplified - in real RAG, this would use a language model)
    answer = f"Based on retrieved knowledge: {' '.join(retrieved_docs)}"

    return answer

# Example usage
query = "How do neural networks work?"
result = rag_query(query)
print(f"Query: {query}")
print(f"Answer: {result}")
        """)

    else:
        print(f"Sample implementation for {model_name} not shown for brevity.")

# Demonstrate a couple of models
demonstrate_model("Logistic Regression")
demonstrate_model("RAG Model (Retrieval-Augmented Generation)")

!pip install datasets